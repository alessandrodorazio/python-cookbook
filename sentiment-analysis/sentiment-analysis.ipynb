{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58edf031",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Autore: [Alessandro D'Orazio](https://alessandrodorazio.it) per [parliamodiai.it](https://parliamodiai.it)\n",
    "\n",
    "In questo notebook, vengono mostrare delle tecniche per fare l'analisi del sentiment, cioè capire, partendo da un testo, se questo sia positivo o negativo. Utilizzeremo un dataset disponibile pubblicamente in cui vengono associate delle recensioni di Amazon ad un valore positivo nel caso in cui la recensione sia positiva, negativa altrimenti. <br>\n",
    "Questo tipo di esercizio è detto di classificazione, poiché dati degli input (testi), essi devono essere inseriti in delle classi (sentiment positivo o negativo).\n",
    "\n",
    "Verranno impiegati degli algoritmi base di AI, come:\n",
    "\n",
    "- Regressione Logistica\n",
    "- Support Vector Machine\n",
    "- Random Forest Classifier\n",
    "\n",
    "Successivamente, viene utilizzato l'[Ensemble Learning](https://it.wikipedia.org/wiki/Apprendimento_d%27insieme) per capire se possiamo trarre benefici da modelli più complessi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importazione delle dipendenze base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3a2ab",
   "metadata": {},
   "source": [
    "# Analisi del dataset\n",
    "\n",
    "Il dataset contiene molte colonne per ogni recensione. Per esempio, sono presenti il nome del prodotto, la categoria, il marketplace in cui è stato effettuato l'acquisto (nazione) etc.\n",
    "\n",
    "Essendo questo un esercizio di NLP, andremo ad utilizzare esclusivamente tre colonne: il titolo della recensione, il testo della recensione e il valore del sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a9dde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great love it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lots of ads Slow processing speed Occasionally...</td>\n",
       "      <td>Lots of ads&lt;br /&gt;Slow processing speed&lt;br /&gt;Oc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well thought out device</td>\n",
       "      <td>Excellent unit.  The versatility of this table...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not all apps/games we were looking forward to ...</td>\n",
       "      <td>I bought this on Amazon Prime so I ended up bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>All Amazon products continue to meet my expect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30841</th>\n",
       "      <td>A great upgrade for me from an older Kindle Fire!</td>\n",
       "      <td>[[VIDEOID:moP3B6GS5RL8LY]]I purchased the orig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30842</th>\n",
       "      <td>Great Value for $139</td>\n",
       "      <td>I'm writing this review with the benefit of be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30843</th>\n",
       "      <td>Even grandma has it figured out!</td>\n",
       "      <td>I purchased this Kindle for my grandma, becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30844</th>\n",
       "      <td>The Honda Accord of Tablets</td>\n",
       "      <td>I bought my tablet Fire HD 7 at Best Buy on th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30845</th>\n",
       "      <td>won't regret it</td>\n",
       "      <td>Am impressive piece of hardware for the $. No ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_headline  \\\n",
       "0                                             Five Stars   \n",
       "1      Lots of ads Slow processing speed Occasionally...   \n",
       "2                                Well thought out device   \n",
       "3      Not all apps/games we were looking forward to ...   \n",
       "4                                             Five Stars   \n",
       "...                                                  ...   \n",
       "30841  A great upgrade for me from an older Kindle Fire!   \n",
       "30842                               Great Value for $139   \n",
       "30843                   Even grandma has it figured out!   \n",
       "30844                        The Honda Accord of Tablets   \n",
       "30845                                    won't regret it   \n",
       "\n",
       "                                             review_body  sentiment  \n",
       "0                                          Great love it          1  \n",
       "1      Lots of ads<br />Slow processing speed<br />Oc...          0  \n",
       "2      Excellent unit.  The versatility of this table...          1  \n",
       "3      I bought this on Amazon Prime so I ended up bu...          1  \n",
       "4      All Amazon products continue to meet my expect...          1  \n",
       "...                                                  ...        ...  \n",
       "30841  [[VIDEOID:moP3B6GS5RL8LY]]I purchased the orig...          1  \n",
       "30842  I'm writing this review with the benefit of be...          1  \n",
       "30843  I purchased this Kindle for my grandma, becaus...          1  \n",
       "30844  I bought my tablet Fire HD 7 at Best Buy on th...          1  \n",
       "30845  Am impressive piece of hardware for the $. No ...          1  \n",
       "\n",
       "[30846 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('product-reviews.csv', usecols=['review_headline', 'review_body', 'sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af16c1",
   "metadata": {},
   "source": [
    "# Preprocessamento del testo\n",
    "\n",
    "## Stop Words\n",
    "\n",
    "Ogni recensione è scritta in linguaggio naturale, cioè il linguaggio che utilizziamo comunemente quando scriviamo qualcosa. Il linguaggio naturale contiene tante stop words, cioè parole comuni che non riguardano uno specifico argomento. Rientrano nelle stop words gli articoli, le preposizioni e le congiunzioni, poiché sono parole che possiamo ritrovare in ogni testo.\n",
    "\n",
    "Considerando la seguente frase: \"L'intelligenza artificiale è la capacità di un sistema artificiale di simulare l'intelligenza umana\", possiamo considerare come stop words: `L'`, `la`, `di`, `un`. Questo significa che, rimuovendo le stop words, il testo diventa: 'intelligenza artificiale è capacità sistema artificiale simulare intelligenza umana'.\n",
    "\n",
    "È importante rimuovere le stop words nell'ambito del NLP poiché esse potrebbero indurre i modelli in errore, per esempio, aumentando la possibilità per cui le recensioni contenenti la parola \"La\" vengano contrassegnate come positive o negative solo perché presente questo articolo.\n",
    "\n",
    "In Python esiste un package chiamato `nltk` che fornisce delle utility nell'ambito del linguaggio naturale.\n",
    "\n",
    "## Tokenizzazione\n",
    "\n",
    "Un altro step molto importante è quello di tokenizzare i testi. In pratica, partendo da una stringa composta da 100 parole, attraverso la tokenizzazione la stringa viene convertita in un array di 100 elementi.\n",
    "\n",
    "Dunque, riprendendo la frase \"L'intelligenza artificiale è la capacità di un sistema artificiale di simulare l'intelligenza umana\" il risultato sarà:\n",
    "```\n",
    "[\"L'intelligenza\",\n",
    " 'artificiale',\n",
    " 'è',\n",
    " 'la',\n",
    " 'capacità',\n",
    " 'di',\n",
    " 'un',\n",
    " 'sistema',\n",
    " 'artificiale',\n",
    " 'di',\n",
    " 'simulare',\n",
    " \"l'intelligenza\",\n",
    " 'umana']```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2600f4",
   "metadata": {},
   "source": [
    "## Altre tecniche per il processamento\n",
    "\n",
    "Esistono molte altre tecniche per il processamento dei testi, per esempio lo [stemming](https://it.wikipedia.org/wiki/Stemming) e la [lemmization](https://en.wikipedia.org/wiki/Lemmatization), che non utilizzeremo in questo notebook poiché saranno approfondite in altri notebook.\n",
    "\n",
    "Una tecnica che utilizzeremo sarà invece quella di trasformare tutte le lettere in minuscolo, in modo tale da non avere differenza tra una parola scritta tutta in minuscolo ed una scritta tutta in maiuscolo (artificiale vs ARTIFICIALE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc0598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrodorazio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandrodorazio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str) is not True:\n",
    "        return []\n",
    "    stop_words = set(stopwords.words('english')) # il dataset è in inglese, dunque utilizziamo le stop words inglesi\n",
    "    tokens = word_tokenize(text)\n",
    "    processed_tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token.isalpha()]\n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f81145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title_tokens  \\\n",
      "0                                          [five, stars]   \n",
      "1      [lots, ads, slow, processing, speed, occasiona...   \n",
      "2                                [well, thought, device]   \n",
      "3      [looking, forward, using, compatible, tablet, ...   \n",
      "4                                          [five, stars]   \n",
      "...                                                  ...   \n",
      "30841              [great, upgrade, older, kindle, fire]   \n",
      "30842                                     [great, value]   \n",
      "30843                           [even, grandma, figured]   \n",
      "30844                           [honda, accord, tablets]   \n",
      "30845                                       [wo, regret]   \n",
      "\n",
      "                                             body_tokens  \n",
      "0                                          [great, love]  \n",
      "1      [lots, ads, br, slow, processing, speed, br, o...  \n",
      "2      [excellent, unit, versatility, tablet, besides...  \n",
      "3      [bought, amazon, prime, ended, buying, one, ca...  \n",
      "4       [amazon, products, continue, meet, expectations]  \n",
      "...                                                  ...  \n",
      "30841  [videoid, purchased, original, kindle, fire, s...  \n",
      "30842  [writing, review, benefit, experienced, kindle...  \n",
      "30843  [purchased, kindle, grandma, wanted, simple, w...  \n",
      "30844  [bought, tablet, fire, hd, best, buy, day, cam...  \n",
      "30845  [impressive, piece, hardware, regrets, girlfri...  \n",
      "\n",
      "[30846 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['title_tokens'] = df['review_headline'].apply(preprocess_text)\n",
    "df['body_tokens'] = df['review_body'].apply(preprocess_text)\n",
    "print(df[['title_tokens', 'body_tokens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574ddd3",
   "metadata": {},
   "source": [
    "Dato che i modelli avranno solamente un testo in input, andiamo a concatenare il titolo e il corpo della recensione in un'unica colonna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab971c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               [five, stars, great, love]\n",
       "1        [lots, ads, slow, processing, speed, occasiona...\n",
       "2        [well, thought, device, excellent, unit, versa...\n",
       "3        [looking, forward, using, compatible, tablet, ...\n",
       "4        [five, stars, amazon, products, continue, meet...\n",
       "                               ...                        \n",
       "30841    [great, upgrade, older, kindle, fire, videoid,...\n",
       "30842    [great, value, writing, review, benefit, exper...\n",
       "30843    [even, grandma, figured, purchased, kindle, gr...\n",
       "30844    [honda, accord, tablets, bought, tablet, fire,...\n",
       "30845    [wo, regret, impressive, piece, hardware, regr...\n",
       "Name: review_tokens, Length: 30846, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_tokens'] = df['title_tokens'] + df['body_tokens']\n",
    "df['review_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77576ec1",
   "metadata": {},
   "source": [
    "# Vettorizzazione\n",
    "\n",
    "I modelli di intelligenza artificiale non sono in grado di lavorare con le parole, poiché necessitano di rappresentazioni matematiche. <br>\n",
    "Per trasformare una parola in una rappresentazione matematica, vengono utilizzate delle tecniche di vettorizzazione.\n",
    "\n",
    "## [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "\n",
    "Questa è la tecnica più semplice. In pratica, viene creato un vocabolario con tutte le parole utilizzate, e per ogni parola viene associato il numero di occorrenze.\n",
    "\n",
    "\n",
    "## [TF-IDF](https://it.wikipedia.org/wiki/Tf-idf)\n",
    "\n",
    "Attraverso TF-IDF (acronimo di Term Frequency-Inverse Document Frequency), viene calcolata l'importanza di una parola all'interno di un documento. <br>\n",
    "Vengono calcolati due valori:\n",
    "\n",
    "- Term Frequency (TF): la frequenza della parola nei documenti, cioè la percentuale di volte che viene utilizzata una determinata parola. Per esempio, se la parola \"artificiale\" è presente 5 volte nel documento 57, contenente 100 parole, allora TF(artificiale, 57)=5%. <br><br>\n",
    "\n",
    "- Inverse Document Frequency (IDF): quanto è specifica una parola all'interno dei documenti. Viene computato per evitare che parole che compaiono molto spesso (es. stop words) non abbiano troppo peso rispetto a quelle più significative. Viene calcolato tramite il logaritmo del rapporto tra il numero di documenti totali e il numero di documenti in cui appare un dato termine. Dunque, se la parola artificiale compare in 12 documenti su 91, allora IDF(artificiale)=log(91/12)=0,87.\n",
    "\n",
    "Dunque, il valore TF-IDF per ogni parola X nel documento Y, si calcola facendo TF(X, Y)*IDF(X). Più è alto il valore TF-IDF, più quella parola dovrebbe essere significativa.\n",
    "\n",
    "\n",
    "\n",
    "## [Word2Vec](https://it.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "Word2Vec è una rete neurale di word embedding (cioè vettorizzazione tramite deep learning) in cui ogni parola viene rappresentata come un punto in uno spazio multidimensionale. <br>\n",
    "Il suo punto di forza è che date due parole correlate, queste saranno vicine nello spazio, dunque saranno considerate simili o in qualche modo correlate. <br>\n",
    "Al contrario delle tecniche descritte precedentemente, Word2Vec è in grado di catturare anche il significato delle parole nel contesto (mentre Bag of Words e TF-IDF si limitano a contare le occorrenze delle parole).\n",
    "\n",
    "[Paper ufficiale di Word2Vec](https://arxiv.org/pdf/1301.3781)\n",
    "\n",
    "In questo notebook viene utilizzato Word2Vec tramite il package `gensim`, che fornisce delle utility pronte all'uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# addestrare una rete Word2Vec da zero è time consuming, dunque carichiamo un modello già pronto\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72286d9",
   "metadata": {},
   "source": [
    "Dato che alcune parole presenti nelle recensioni non sono nella rete Word2Vec fornita da Gensim, rimuoveremo queste parole.<br>\n",
    "In un ambito di produzione sarebbe opportuno invece riaddestrare la rete da zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b076fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.056793213, 0.036499023, 0.0335083, 0.146362...\n",
       "1        [0.091103144, 0.02632795, -0.03199986, 0.06162...\n",
       "2        [0.032694574, 0.04096225, -0.065703206, 0.0583...\n",
       "3        [0.050921816, 0.016914137, -0.007219565, 0.107...\n",
       "4        [-0.11839076, 0.11945452, 0.010864258, 0.14957...\n",
       "                               ...                        \n",
       "30841    [0.02131028, 0.03754676, -0.022550864, 0.04066...\n",
       "30842    [0.050956424, 0.034219164, -0.02223143, 0.0548...\n",
       "30843    [0.048681132, 0.022238566, -0.016763305, 0.093...\n",
       "30844    [0.02453538, 0.062008925, -0.029453654, 0.0401...\n",
       "30845    [0.060272217, 0.011199951, 0.027770996, 0.0010...\n",
       "Name: doc_vector, Length: 30846, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def document_vector(doc):\n",
    "    doc = [word for word in doc if word in model]\n",
    "    if len(doc) > 0:\n",
    "        return np.mean(model[doc], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size,)\n",
    "\n",
    "df['doc_vector'] = df['review_tokens'].apply(document_vector)\n",
    "df['doc_vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370056c",
   "metadata": {},
   "source": [
    "# Creazione dei dataset di training e test \n",
    "\n",
    "Andiamo ora a creare i dataset, in cui l'80% sarà per il training ed il restante 20% per il test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412e04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(list(df['doc_vector']))\n",
    "y = np.array(df['sentiment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a905d",
   "metadata": {},
   "source": [
    "# Creazione e valutazione dei modelli\n",
    "\n",
    "Come anticipato precedentemente, andremo ad utilizzare tre modelli differenti per analizzare quale ci fornirà il risultato più accurato.\n",
    "\n",
    "## Metriche per la valutazione\n",
    "\n",
    "Prima della valutazione dei modelli, è necessario parlare di alcune nozioni preliminari:\n",
    "- True positive: predizioni corrette con output vero\n",
    "- True negative: predizioni corrette con output falso\n",
    "- False positive: predizioni errate con output vero\n",
    "- False negative: predizioni errate con output falso\n",
    "\n",
    "Andremo a valutare i modelli utilizzando le seguenti metriche.\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "L'accuracy rappresenta la percentuale di predizioni che il modello ha indovinato.\n",
    "\n",
    "$$\\text{Accuracy}=\\frac {\\text{Predizioni Corrette}} {\\text{Predizioni totali}}$$\n",
    "\n",
    "#### Precision\n",
    "\n",
    "La precision rappresenta l'accuratezza delle predizioni positive.\n",
    "\n",
    "$$\\text{Precision}=\\frac{\\text{True positive}} {\\text{True positive + False Positive}}$$\n",
    "\n",
    "\n",
    "#### Recall\n",
    "\n",
    "Il recall rappresenta il rapporto tra le predizioni vere corrette e le predizioni che dovevano essere contrassegnate come vere ma che sono state contrassegnate come false.\n",
    "\n",
    "$$\\text{Recall}=\\frac{\\text{True Positive}} {\\text{True Positive + False Negative}}$$\n",
    "\n",
    "#### F1-Score\n",
    "\n",
    "L'F1-Score è una misura pesata tra precision e recall.<br>\n",
    "Rappresenta quanto la precision e la recall siano bilanciate tra di loro. Un valore più elevato indica genericamente un modello complessivamente migliore.\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\text{F1-Score}=2 * \\left( \\frac {\\text{Precision}*\\text{Recall}} {\\text{Precision}+\\text{Recall}} \\right)\n",
    "\\\n",
    "$$\n",
    "\n",
    "#### Support\n",
    "\n",
    "Quanti elementi sono stati valutati.\n",
    "\n",
    "\n",
    "## [Regressione Logistica](https://it.wikipedia.org/wiki/Modello_logit)\n",
    "\n",
    "La regressione logistica è un modello statistico per modellare la probabilità di un risultato binario (vero/falso).<br>\n",
    "\n",
    "All'atto pratico, nella regressione logistica, l'addestramento consiste nel determinare i pesi da applicare durante le predizioni, che avvengono tramite il calcolo di una combinazione lineare. I pesi vengono tipicamente stabiliti utilizzando un'estimator chiamato [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#:~:text=In%20statistics%2C%20maximum%20likelihood%20estimation,observed%20data%20is%20most%20probable.)<br>\n",
    "Successivamente, viene applicata una funzione sigmoide (detta anche logistica, da qui il nome), che porterà l'output della combinazione lineare in un range compreso tra 0 e 1. <br>\n",
    "Infine, il valore ottenuto dalla funzione sigmoide servirà al modello per decidere se rispondere vero o falso. In pratica, viene stabilito un threshold, e se il valore è maggiore di questo threshold, allora il modello risponderà vero, altrimenti falso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7d9f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['model', 'accuracy', 'precision', 'recall', 'f1', 'elapsed']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_metrics = {}\n",
    "results_metrics = [['model', 'accuracy', 'precision', 'recall', 'f1', 'elapsed']]\n",
    "results_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e55106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Evaluation:\n",
      "Elapsed: 897.31, Accuracy: 0.90, Precision: 0.92, Recall: 0.96, F1-Score: 0.94\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66      1018\n",
      "           1       0.92      0.96      0.94      5152\n",
      "\n",
      "    accuracy                           0.90      6170\n",
      "   macro avg       0.83      0.78      0.80      6170\n",
      "weighted avg       0.89      0.90      0.89      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "start = timer()\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train) # addestramento\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# valutazione del modello\n",
    "elapsed_lr = (timer() - start)*1000\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "precision_lr = precision_score(y_test, y_pred)\n",
    "recall_lr = recall_score(y_test, y_pred)\n",
    "f1_lr = f1_score(y_test, y_pred)\n",
    "\n",
    "results_metrics.append(['Logistic Regression', accuracy_lr, precision_lr, recall_lr, f1_lr, elapsed_lr])\n",
    "\n",
    "print(\"Logistic Regression Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_lr:.2f}, Accuracy: {accuracy_lr:.2f}, Precision: {precision_lr:.2f}, Recall: {recall_lr:.2f}, F1-Score: {f1_lr:.2f}\")\n",
    "print(\"\\nClassification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927fe9e",
   "metadata": {},
   "source": [
    "## [Support Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "\n",
    "Le Support Vector Machine sono dei modelli di machine learning supervisionato che impiegano il concetto di [iperpiano](https://en.wikipedia.org/wiki/Hyperplane). <br>\n",
    "Prendendo in considerazione un piano a due dimensioni, l'iperpiano è una linea di separazione. Viene impiegata in modo tale che i punti disposti da una parte della linea siano considerati come veri, mentre i punti dall'altra parte della linea come falsi. <br>\n",
    "Il concetto di iperpiano si applica anche con piano con più dimensioni.\n",
    "\n",
    "Una nozione fondamentale è quella del margine, cioè la distanza tra i punti più vicini che forniscono output differenti. Questi punti sono critici, poiché definiscono (o supportano) l'iperpiano e vengono chiamati support vector.\n",
    "\n",
    "Forme di SVM:\n",
    "\n",
    "- Lineari, cioè quelli in cui l'iperpiano generato è lineare nella sua accezione matematica\n",
    "- Non lineari, cioè quando i dati non sono separabili linearmente, e dunque è necessario trasformare i dati in modo tale che arrivino ad una dimensione tale per cui sia possibile costruire un iperpiano lineare per separare i dati\n",
    "\n",
    "Quando viene addestrata una SVM, il modello prova a trovare l'iperpiano corretto risolvendo un problema di ottimizzazione che massimizzi il margine.\n",
    "\n",
    "Nell'esempio sarà utilizzato un kernel lineare, cioè in cui non avvengono trasformazioni rispetto allo spazio delle feature. Nel caso invece di un kernel polinomiale, i dati vengono trasformati in uno spazio polinomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c237e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Evaluation:\n",
      "Elapsed:  35421.15, Accuracy: 0.90, Precision: 0.93, Recall: 0.96, F1-Score: 0.94\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67      1018\n",
      "           1       0.93      0.96      0.94      5152\n",
      "\n",
      "    accuracy                           0.90      6170\n",
      "   macro avg       0.83      0.78      0.81      6170\n",
      "weighted avg       0.90      0.90      0.90      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start = timer()\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "elapsed_svm = (timer() - start)*1000\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "results_metrics.append(['Support Vector Machine', accuracy_svm, precision_svm, recall_svm, f1_svm, elapsed_svm])\n",
    "\n",
    "print(\"SVM Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_svm: .2f}, Accuracy: {accuracy_svm:.2f}, Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}\")\n",
    "print(\"\\nClassification Report for SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eba681",
   "metadata": {},
   "source": [
    "## [Random Forest](https://en.wikipedia.org/wiki/Random_forest)\n",
    "\n",
    "Prima di parlare di Random Forest, bisogna parlare di [alberi di decisione](https://it.wikipedia.org/wiki/Albero_di_decisione). <br>\n",
    "Un albero di decisione è un grafo aciclico in cui ogni conseguenza di una possibile decisione (es. valore X maggiore di 5) viene ramificata. Nel machine learning ogni nodo rappresenta una variabile (es. valore X) e i suoi figli rappresentano i valori possibili. <br>\n",
    "Le foglie rappresentano il valore predetto. Per capire come è stato predetto il valore, è sufficiente attraversare l'albero dalla radice alla foglia.\n",
    "\n",
    "I Random Forest sono un modello in cui vengono utilizzati molti alberi di decisione in modo tale da catturare più aspetti del dataset in ingresso. Nella classificazione, tipicamente il valore predetto è ciò che \"votano\" la maggior parte degli alberi, mentre nella regressione è la media tra i valori predetti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f73492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Evaluation:\n",
      "Elapsed:  30403.26, Accuracy: 0.88, Precision: 0.89, Recall: 0.98, F1-Score: 0.93\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.38      0.51      1018\n",
      "           1       0.89      0.98      0.93      5152\n",
      "\n",
      "    accuracy                           0.88      6170\n",
      "   macro avg       0.83      0.68      0.72      6170\n",
      "weighted avg       0.87      0.88      0.86      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = timer()\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 alberi nella foresta\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "elapsed_rf = (timer() - start)*1000\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "results_metrics.append(['Random Forest', accuracy_rf, precision_rf, recall_rf, f1_rf, elapsed_rf])\n",
    "\n",
    "print(\"Random Forest Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_rf: .2f}, Accuracy: {accuracy_rf:.2f}, Precision: {precision_rf:.2f}, Recall: {recall_rf:.2f}, F1-Score: {f1_rf:.2f}\")\n",
    "print(\"\\nClassification Report for Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d8666",
   "metadata": {},
   "source": [
    "# Analisi dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "534cc331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>897.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>35421.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>30403.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  precision  recall    f1   elapsed\n",
       "0     Logistic Regression      0.90       0.92    0.96  0.94    897.31\n",
       "1  Support Vector Machine      0.90       0.93    0.96  0.94  35421.15\n",
       "2           Random Forest      0.88       0.89    0.98  0.93  30403.26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_metrics[1:], columns=results_metrics[0]).round({'accuracy': 2, 'precision': 2, 'recall': 2, 'f1': 2, 'elapsed': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f8a7b",
   "metadata": {},
   "source": [
    "Come possiamo vedere, la regressione logistica e l'SVM hanno un accuracy ed una precision maggiore rispetto alle Random Forest.\n",
    "\n",
    "Allo stesso tempo, il recall è migliore nelle Random Forest, poiché riesce a gestire meglio i casi di False Negative, cioè quei casi che dovrebbero essere veri ma che il modello predice come falsi.\n",
    "\n",
    "L'F1-Score invece è tutto sommato simile, il che non ci porta ad avere una preferenza marcata.\n",
    "\n",
    "La regressione logistica ha il minor costo computazionale, e per questo potrebbe essere considerato come il modello migliore in questa casistica. Se invece diamo molta importanza al non avere falsi negativi, le Random Forest sono quelle che performano meglio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51868ea",
   "metadata": {},
   "source": [
    "# [Ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning)\n",
    "\n",
    "Passiamo ora all'Ensemble Learning, una modalità di apprendimento in cui vengono utilizzati più modelli sequenzialmente per aumentare l'accuratezza. <br> \n",
    "Anche le Random Forest sono considerate come esempio di Ensemble Learning, poiché partendo da alberi di decisione, ne vengono creati molti e utilizzati insieme per predire un valore. <br>\n",
    "\n",
    "## [Bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating)\n",
    "\n",
    "In particolare, le Random Forest utilizzano una tecnica chiamata **Bagging** (detto anche bootstrap aggregating), in cui vengono creati molti sottoinsiemi del dataset di partenza tramite il bootstrap sampling (ogni sottoinsieme è composto da elementi presi dal dataset e ogni elemento può comparire più di una volta). Successivamente, ogni modello viene addestrato su uno tra i sample creati. Infine, i risultati finali dipendono dalle predizioni di ogni modello. <br>\n",
    "Nell'ambito della classificazione, solitamente vince la maggioranza, mentre nella regressione la media tra tutte le predizioni.\n",
    "\n",
    "\n",
    "In questo notebook sono presenti tre tecniche per l'Ensemble Learning:\n",
    "- AdaBoost\n",
    "- Gradient Boosting\n",
    "- Stacking\n",
    "\n",
    "Prima di analizzare questi tre algoritmi, dobbiamo parlare di Gradient Descent.\n",
    "\n",
    "## [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)\n",
    "\n",
    "Partiamo dalla nozione di [gradient](https://en.wikipedia.org/wiki/Gradient): il gradient è un vettore che punta alla direzione del massimo tasso di aumento di una funzione scalare, e la sua grandezza corrisponde al tasso di aumento in quella direzione. <br>\n",
    "Il Gradient Descent è un algoritmo di ottimizzazione per trovare dei coefficienti che minimizzino una funzione di costo il più possibile. L'idea alla base è di modificare i parametri iterativamente per minimizzare questa funzione di costo. La funzione di costo misura l'errore del modello. <br>\n",
    "Nel Gradient Descent, il gradient è riferito alla funzione di costo, che fornisce la direzione per la salita più ripida. Muovendosi quindi in direzione opposta, è possibile ridurre l'errore. <br>\n",
    "Più tecnicamente, si parte con dei valori iniziali per i parametri (coefficienti/pesi), e viene calcolato il gradient della funzione di costo rispetto ad ogni parametro. Successivamente, vengono modificati i parametri nella direzione che più riduce il costo. Vengono ripetuti questi step finché le modifiche tra un'iterazione e l'altra è molto piccola. È importante effettuare più iterazioni poiché il calcolo del gradient è basato sulla pendenza locale, quindi ci vogliono più iterazioni per raggiungere il minimo.\n",
    "\n",
    "### Tipologie di Gradient Descent\n",
    "\n",
    "- Batch Gradient Descent: computa il gradient della funzione di costo utilizzando l'intero dataset (computazionalmente costoso ma consistente)\n",
    "- Stochastic Gradient Descent: utilizza un singolo sample alla volta, ma gli aggiornamenti potrebbero essere più \"sporchi\"\n",
    "- Mini-batch Gradient Descent: computa il gradient e aggiorna i parametri utilizzando un sottoinsieme del dataset\n",
    "\n",
    "# [Boosting](https://it.wikipedia.org/wiki/Boosting)\n",
    "\n",
    "Il Boosting è una tecnica di Ensemble Learning che consiste nel combinare dei weak learners (algoritmi di learning semplici) in maniera sequenziale al fine di creare uno \"strong learner\", cioè un modello più accurato. <br>\n",
    "Ogni weak learner, teoricamente, dovrebbe fornire dei risultati di poco migliori rispetto allo sparare a caso.  L'idea è che attraverso la loro combinazione venga prodotto un modello molto accurato. <br>\n",
    "Ogni weak learner migliorerà le capacità del modello imparando dagli errori dei modelli precedenti, poiché si focalizza sui dati di addestramento che sono stato predetti male dai learner precedenti. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f008d5c",
   "metadata": {},
   "source": [
    "# [AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)\n",
    "\n",
    "AdaBoost è un algoritmo di Boosting in cui i weak learners vengono combinati attraverso una somma pesata che rappresenta l'output finale. <br>\n",
    "Dopo ogni iterazione, AdaBoost modifica i pesi delle istanze classificate in maniera errata in modo tale che i modelli successivi si possano focalizzare sulle casistiche più difficili. In pratica, prova a correggere gli errori aumentando il peso dei punti classificati erroneamente. I modelli con l'accuracy più alta influiranno maggiormente sulla predizione, computata come la somma pesata delle predizioni dei modelli weak.<br>\n",
    "Utilizzeremo degli alberi di decisione come weak learners (che vengono impostati di default). <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66185af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Model Evaluation:\n",
      "Elapsed:  66402.29, Accuracy: 0.89, Precision: 0.92, Recall: 0.95, F1-Score: 0.93\n",
      "\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.62      1018\n",
      "           1       0.92      0.95      0.93      5152\n",
      "\n",
      "    accuracy                           0.89      6170\n",
      "   macro avg       0.80      0.76      0.78      6170\n",
      "weighted avg       0.88      0.89      0.88      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start = timer()\n",
    "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "y_pred_ada = ada_boost.predict(X_test)\n",
    "\n",
    "elapsed_ada = (timer() - start)*1000\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "\n",
    "results_metrics.append(['AdaBoost', accuracy_ada, precision_ada, recall_ada, f1_ada, elapsed_ada])\n",
    "\n",
    "print(\"AdaBoost Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_ada: .2f}, Accuracy: {accuracy_ada:.2f}, Precision: {precision_ada:.2f}, Recall: {recall_ada:.2f}, F1-Score: {f1_ada:.2f}\")\n",
    "print(\"\\nClassification Report for AdaBoost:\")\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192034e7",
   "metadata": {},
   "source": [
    "# [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)\n",
    "\n",
    "Nel Gradient Boosting, ogni albero di decisione viene costruito utilizzando l'errore residuale degli alberi precedenti. <br> \n",
    "Per errore residuale si intende la differenza tra il valore computato e il valore attuale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e18ff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Evaluation:\n",
      "Elapsed:  171424.11, Accuracy: 0.89, Precision: 0.91, Recall: 0.96, F1-Score: 0.94\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.62      1018\n",
      "           1       0.91      0.96      0.94      5152\n",
      "\n",
      "    accuracy                           0.89      6170\n",
      "   macro avg       0.83      0.75      0.78      6170\n",
      "weighted avg       0.88      0.89      0.89      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start = timer()\n",
    "gradient_boost = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gradient_boost.fit(X_train, y_train)\n",
    "y_pred_gb = gradient_boost.predict(X_test)\n",
    "\n",
    "elapsed_gb = (timer() - start)*1000\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "precision_gb = precision_score(y_test, y_pred_gb)\n",
    "recall_gb = recall_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb)\n",
    "\n",
    "results_metrics.append(['Gradient Boosting', accuracy_gb, precision_gb, recall_gb, f1_gb, elapsed_gb])\n",
    "\n",
    "print(\"Gradient Boosting Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_gb: .2f}, Accuracy: {accuracy_gb:.2f}, Precision: {precision_gb:.2f}, Recall: {recall_gb:.2f}, F1-Score: {f1_gb:.2f}\")\n",
    "print(\"\\nClassification Report for Gradient Boosting:\")\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f09da5",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost è un'implementazione avanzata del Gradient Boosting, più veloce e tipicamente più performante. <br>\n",
    "Include una [regolarizzazione](https://en.wikipedia.org/wiki/Regularization_(mathematics)) L1 ([Lasso](https://en.wikipedia.org/wiki/Lasso_(statistics))) e L2 ([Ridge](https://en.wikipedia.org/wiki/Ridge_regression)) che previene problematiche comuni come l'overfitting. <br>\n",
    "Al contrario del Gradient Boosting, XGBoost sviluppa gli alberi di decisione fino alla loro massima profondità e successivamente li riduce per aumentare l'efficienza. <br>\n",
    "Un'altra caratteristica di XGBoost è che effettua una cross validation ad ogni iterazione, rendendo più semplice il processo di decisione riguardo i round di boosting per prevenire l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeaf167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Evaluation:\n",
      "Elapsed: 1706.86, Accuracy: 0.90, Precision: 0.92, Recall: 0.96, F1-Score: 0.94\n",
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66      1018\n",
      "           1       0.92      0.96      0.94      5152\n",
      "\n",
      "    accuracy                           0.90      6170\n",
      "   macro avg       0.83      0.78      0.80      6170\n",
      "weighted avg       0.89      0.90      0.89      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "start = timer()\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "elapsed_xgb = (timer() - start)*1000\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "results_metrics.append(['XGBoost', accuracy_xgb, precision_xgb, recall_xgb, f1_xgb, elapsed_xgb])\n",
    "\n",
    "print(\"XGBoost Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_xgb:.2f}, Accuracy: {accuracy_xgb:.2f}, Precision: {precision_xgb:.2f}, Recall: {recall_xgb:.2f}, F1-Score: {f1_xgb:.2f}\")\n",
    "print(\"\\nClassification Report for XGBoost:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11277150",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Lo Stacking è una tecnica che combina molti modelli differenti in un unico modello, per esempio utilizzando una regressione logistica e una Random Forest. <br>\n",
    "È composto da due livelli:\n",
    "1. Modelli base: gli algoritmi che saranno eseguiti (es. regressione logistica, SVM etc)\n",
    "2. Meta Learner: modello che viene addestrato basandosi sugli output dei modelli base per combinare al meglio i risultati\n",
    "\n",
    "Dato che vengono utilizzati modelli base differenti, allora ci aspettiamo che possano essere catturati pattern di dati differenti e che quindi si possa raggiungere una maggior accuracy. <br>\n",
    "Un problema dello stacking potrebbe essere l'[overfitting](https://it.wikipedia.org/wiki/Overfitting), cioè l'avere un modello troppo complesso (tanti parametri) rispetto al numero di dati da osservare. Sebbene tutti i modelli presenti in questo notebook possano soffrire di overfitting, lo Stacking è quello che può soffrirne di più, essendo il modello più complesso. <br>\n",
    "Potrebbe quindi succedere che, tornando al problema originale, nel caso in cui sia presente una data parola in tutte le recensioni positive (es. la parola \"stelle\", come nelle recensioni in cui viene detto \"cinque stelle\"), allora il modello potrebbe fornire delle predizioni errate quando presente la suddetta parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e87154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Model Evaluation:\n",
      "Elapsed:  290999.21, Accuracy: 0.90, Precision: 0.93, Recall: 0.96, F1-Score: 0.94\n",
      "\n",
      "Classification Report for Stacking Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68      1018\n",
      "           1       0.93      0.96      0.94      5152\n",
      "\n",
      "    accuracy                           0.90      6170\n",
      "   macro avg       0.83      0.79      0.81      6170\n",
      "weighted avg       0.90      0.90      0.90      6170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "start = timer()\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svr', SVC(kernel='linear', random_state=42))\n",
    "]\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_classifier.predict(X_test)\n",
    "\n",
    "elapsed_stack = (timer() - start)*1000\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "precision_stack = precision_score(y_test, y_pred_stack)\n",
    "recall_stack = recall_score(y_test, y_pred_stack)\n",
    "f1_stack = f1_score(y_test, y_pred_stack)\n",
    "\n",
    "results_metrics.append(['Stacking', accuracy_stack, precision_stack, recall_stack, f1_stack, elapsed_stack])\n",
    "\n",
    "print(\"Stacking Classifier Model Evaluation:\")\n",
    "print(f\"Elapsed: {elapsed_stack: .2f}, Accuracy: {accuracy_stack:.2f}, Precision: {precision_stack:.2f}, Recall: {recall_stack:.2f}, F1-Score: {f1_stack:.2f}\")\n",
    "print(\"\\nClassification Report for Stacking Classifier:\")\n",
    "print(classification_report(y_test, y_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99bad5",
   "metadata": {},
   "source": [
    "# Valutazione finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc49090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>897.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>35421.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>30403.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>66402.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>171424.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1706.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>290999.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  precision  recall    f1    elapsed\n",
       "0     Logistic Regression      0.90       0.92    0.96  0.94     897.31\n",
       "1  Support Vector Machine      0.90       0.93    0.96  0.94   35421.15\n",
       "2           Random Forest      0.88       0.89    0.98  0.93   30403.26\n",
       "3                AdaBoost      0.89       0.92    0.95  0.93   66402.29\n",
       "4       Gradient Boosting      0.89       0.91    0.96  0.94  171424.11\n",
       "5                 XGBoost      0.90       0.92    0.96  0.94    1706.86\n",
       "6                Stacking      0.90       0.93    0.96  0.94  290999.21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(results_metrics[1:], columns=results_metrics[0])\n",
    "metrics_df.round({'accuracy': 2, 'precision': 2, 'recall': 2, 'f1': 2, 'elapsed': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2f9b2c",
   "metadata": {},
   "source": [
    "Possiamo notare come il modello SVM e lo Stacking abbiano prodotto dei risultati praticamente uguali.\n",
    "\n",
    "Se dobbiamo considerare solamente i modelli Ensemble, sicuramente lo Stacking è quello che performa meglio, ma è anche computazionalmente costoso. Se invece siamo disposti a sacrificare circa l'1% di precision, allora possiamo valutare il modello XGBoost o la regressione logistica che sono invece molto meno costosi (meno di 2 secondi vs 290). <br>\n",
    "Stiamo in ogni caso parlando di valori molto vicini, a discapito invece di un costo computazionale molto differente. <br>\n",
    "\n",
    "In conclusione, nel caso in cui l'aggiornamento del dataset di addestramento (e quindi del modello) avvenga molto poco frequentemente, si potrebbe valutare una SVM. Se invece il dataset cambia molto frequentemente, la scelta migliore potrebbe essere XGBoost o la regressione logistica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
